{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51385561-6e11-4de9-b0d6-ea3b03d56b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.9.0\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - cuda-compiler\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2023.11.17         |  py310h06a4308_0         158 KB\n",
      "    cuda-compiler-12.3.1       |                0           2 KB  nvidia\n",
      "    cuda-cuobjdump-12.3.101    |                0         243 KB  nvidia\n",
      "    cuda-cuxxfilt-12.3.101     |                0         295 KB  nvidia\n",
      "    cuda-nvcc-12.3.103         |                0        58.1 MB  nvidia\n",
      "    cuda-nvprune-12.3.101      |                0          65 KB  nvidia\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        58.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cuda-compiler      nvidia/linux-64::cuda-compiler-12.3.1-0 \n",
      "  cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-12.3.101-0 \n",
      "  cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-12.3.101-0 \n",
      "  cuda-nvcc          nvidia/linux-64::cuda-nvcc-12.3.103-0 \n",
      "  cuda-nvprune       nvidia/linux-64::cuda-nvprune-12.3.101-0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                         2023.7.22-py310h06a4308_0 --> 2023.11.17-py310h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "cuda-compiler-12.3.1 | 2 KB      |                                       |   0% \n",
      "cuda-nvcc-12.3.103   | 58.1 MB   |                                       |   0% \u001b[A\n",
      "\n",
      "cuda-cuxxfilt-12.3.1 | 295 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2023.11.17   | 158 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cuda-nvprune-12.3.10 | 65 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cuda-cuobjdump-12.3. | 243 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   |                                       |   0% \u001b[A\n",
      "\n",
      "\n",
      "cuda-compiler-12.3.1 | 2 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "cuda-cuxxfilt-12.3.1 | 295 KB    | ##                                    |   5% \u001b[A\u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | 2                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cuda-nvprune-12.3.10 | 65 KB     | #########                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "cuda-compiler-12.3.1 | 2 KB      | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2023.11.17   | 158 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "certifi-2023.11.17   | 158 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cuda-nvprune-12.3.10 | 65 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "cuda-cuxxfilt-12.3.1 | 295 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | ####8                                 |  13% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cuda-cuobjdump-12.3. | 243 KB    | ##4                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cuda-cuobjdump-12.3. | 243 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | #######4                              |  20% \u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | ###########4                          |  31% \u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | ################5                     |  45% \u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | #####################9                |  59% \u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | ##########################1           |  71% \u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | ##############################5       |  82% \u001b[A\n",
      "cuda-nvcc-12.3.103   | 58.1 MB   | ###################################5  |  96% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c nvidia cuda-compiler -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4d7f2f-c3f1-4d7a-9b34-a688e3e12534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers>=4.32.0\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.24.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting einops\n",
      "  Using cached einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting transformers_stream_generator==0.0.4\n",
      "  Using cached transformers-stream-generator-0.0.4.tar.gz (12 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting peft\n",
      "  Using cached peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting deepspeed\n",
      "  Using cached deepspeed-0.12.3.tar.gz (1.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.32.0)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.32.0)\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers>=4.32.0)\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers>=4.32.0)\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.1)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ninja (from deepspeed)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting py-cpuinfo (from deepspeed)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting pydantic (from deepspeed)\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pynvml (from deepspeed)\n",
      "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.32.0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.32.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0) (2023.11.17)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->deepspeed)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic->deepspeed)\n",
      "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading peft-0.6.2-py3-none-any.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: transformers_stream_generator, deepspeed\n",
      "  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.4-py3-none-any.whl size=12315 sha256=a62f0cc665344e608e1fa040c38bff8adb34fdbc008ee1cac11e6074417f5198\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/1d/3c/92d88493ed40c0d9be60a391eb76c9a56e9f9b7542cb789401\n",
      "  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.12.3-py3-none-any.whl size=1279161 sha256=6878606bc69e5ff75d71e12569ad1adf487e6f1c251490351375e8795d3dfd1a\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/2b/c5/892ceee06964ce8aa2a98d4260848d0d9a3f1e743862e4b45a\n",
      "Successfully built transformers_stream_generator deepspeed\n",
      "Installing collected packages: py-cpuinfo, ninja, hjson, scipy, safetensors, regex, pynvml, pydantic-core, einops, annotated-types, tiktoken, pydantic, huggingface-hub, tokenizers, deepspeed, accelerate, transformers, transformers_stream_generator, peft\n",
      "Successfully installed accelerate-0.24.1 annotated-types-0.6.0 deepspeed-0.12.3 einops-0.7.0 hjson-3.1.0 huggingface-hub-0.19.4 ninja-1.11.1.1 peft-0.6.2 py-cpuinfo-9.0.0 pydantic-2.5.2 pydantic-core-2.14.5 pynvml-11.5.0 regex-2023.10.3 safetensors-0.4.1 scipy-1.11.4 tiktoken-0.5.1 tokenizers-0.15.0 transformers-4.35.2 transformers_stream_generator-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers>=4.32.0\" accelerate tiktoken einops scipy transformers_stream_generator==0.0.4 peft deepspeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a530f99c-fc44-453d-9e4c-a9c231e34493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.41.2.post2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c88ee3-07b4-41ab-9710-3d104d415dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'flash-attention'...\n",
      "remote: Enumerating objects: 4384, done.\u001b[K\n",
      "remote: Counting objects: 100% (4384/4384), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1214/1214), done.\u001b[K\n",
      "remote: Total 4384 (delta 3079), reused 4132 (delta 2999), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (4384/4384), 6.90 MiB | 6.24 MiB/s, done.\n",
      "Resolving deltas: 100% (3079/3079), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Dao-AILab/flash-attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f9d11c-88f4-4400-8924-9f969a386980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/flash-attention\n"
     ]
    }
   ],
   "source": [
    "%cd flash-attention \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc6f30a-57ea-4286-a4a5-decc0d92d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /flash-attention\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.3.6) (2.1.1)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.3.6) (0.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.3.6) (23.1)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.3.6) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.3.6) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.3.6) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.3.6) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.3.6) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.3.6) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.3.6) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.3.6) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.3.6) (1.3.0)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.3.6-cp310-cp310-linux_x86_64.whl size=56477261 sha256=652ad256d0891cb2c6d7183f96f7f56ff61cdeee24388381abb35e7a0f2eeca1\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/98/ee/51fd7044f9d768b6967dc8f7d83543e559a75f9829f6a55fc8\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: flash-attn\n",
      "Successfully installed flash-attn-2.3.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e21bf88-e92b-4a50-b87c-1311beb69006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-72B-Chat\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98430440-2951-42f4-aa70-e22397b96593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7bbc79f96c441aa26f199373db2b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/48.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606577099cd64a0d9ecea757486c724a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fba3f782ab425cb70fb0e8f111bd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00082.safetensors:   0%|          | 0.00/2.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc3d2c792404f9dbf4cc0a2a4c017d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2a04482df34e0799d150faf34c7da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1796834e95248db84b7e9b437cd8c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f72ed3a6d64afe90484c4a3331fa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6884a1ddb294544bcb6476d784691ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807ad1f017cc40e48727f293cda04276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9c8ed165a749c99d2511c7f97adad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bd266fe2bf4d67b76dd6fcee1a68fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab77508237c4fe58c6e34b3722ac849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1050f987b1fc4918bda7efa83c48efd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b78b92a2e0244d8903145952b374bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb864ebaa8af4aadbaa5fbccdaf556fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1406598174497697de0af1fdb6ed35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75de11f8d374125b1ce91910ca70305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b266fd84726436a8d9d8b8ce2a6e226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a3acee14eb4a2ba6207a64c415fbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95dc5c59e77e4e39b561f5350857a6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d722375e013c4602aae622be2c5db861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892368283d824127bd948af8d449b8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97e976f97604408865ef3db324eb661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4704aeec3a4a84b4b89b077a9edf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f646b8375b416dbda71e3b3e4f1fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0122580162e34f48977c7f9115742cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dceae951d249a6ac456bcf30f38cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691e9cf1870f42b081120777026ee883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038b2be0dbf242a186a8144cfe6b09e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e83d1c32a94fd5823bdefc22189230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479604e64a594b4b89f970b2e94ffc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9f27ee581a4c72a62945e8b694e809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c07e6d6f9d4a39ae55dd24134cd7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00031-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53a81dd4aa442698e3a20cf27f0c6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00032-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1339f93d6d408a9fa6fa602a499b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00033-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e47d206fed6401ab4feb40f3860b55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00034-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a500752908425eac99d266f0e4a80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00035-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cfbf5e175a40aba1a670397e6dd732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00036-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1535795ef92a4f7c9dab9b9d8c9f1581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00037-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9b031325ee4919b370503b2cd83c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00038-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f24aabee4cb414b9e71decfe3fd4de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00039-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51969cb39e4346238ee36eff3554ddaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00040-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ba3c0e7b3e4bc1a9faaa41c4f443b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00041-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883b3535e363489690311eb1a54bc4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00042-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53713d0b7eab40f292c5b56fe9811b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00043-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff13121fb4042df81330557dafa50e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00044-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c073579cdfc4df8b92fb13372f18c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00045-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b29944a2b349f8a048eb898344be29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00046-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f28c9dd14744a5a0ed8493a46924d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00047-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdc32acdce5400aaff929c9789dcd34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00048-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745d063d7e1646f2b5a9f1c7b7d4e753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00049-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c821c461ac924bc8b3d2badea9c41964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00050-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ac71401cfa4b94bf9d36764cf1484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00051-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19b81e35fbd4e0da21aabdffa3ba323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00052-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c08fe0d5ba24d06829c07d833694bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00053-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df49aff84f8d4c86a25dbc39a9eb1209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00054-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a78e186adcc4b7f830c25b87822f628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00055-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3243dda9ca644feb81b11466b402bfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00056-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4f2c811d574c9889c96d5c8c391f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00057-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0251087cf44d46bd8e10fea1426d4f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00058-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e514b25a7f4eba82d63c87c52bdb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00059-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea24996b9d4426e8ab377c9f18b5739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00060-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92da8df661fb414a8545a1d18f984abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00061-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704820bd0c9a4faabf5de538e3306eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00062-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6aa1b6ede447419229a2698012022d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00063-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b99f9d0d5946049a86c25d67fbb531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00064-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc0e2abd3e846ebbc5895c7300c7bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00065-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70da8865b3724ea1a90ddfc6f969f7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00066-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef48917fb3646cb8aaa53ee77443e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00067-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c450f4da5dd4fc1bfe99c4838dbba73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00068-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c568893800ba43d386412d2927fddf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00069-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8300a8482da74c9aa57314c82f86729f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00070-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3cbef046175425688c7ea349117265b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00071-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5ed73d9d1b4ed0b054829032da067e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00072-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6feb0bd27bb84429a5113318c676ed3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00073-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a307e9ff68d94576b2c076e77d113f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00074-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36881b59b2349428427a0b3009018e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00075-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cc5326e24b41f1bbc4a3f6185a1782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00076-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7641045192045719410e86d225f9fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00077-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c5f33bfd8345928ba6c5f0806ff489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00078-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cd511a86a54b2fa6a9e5e929ef5101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00079-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3ea15456ec48b29c87d252b5a2bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00080-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f993583bb29f4ba3985f88974552652d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00081-of-00082.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2387e159b26f4159956459f1524e1cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00082-of-00082.safetensors:   0%|          | 0.00/2.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15599218cf184b80b0f1f78d5225a725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bec44d4b3454ef1b4bf9bbe49e4e4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-72B-Chat\", device_map=\"auto\", trust_remote_code=True, load_in_8bit=True).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5913e5-dd9f-4da6-bad5-3fd86b0984fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-72B-Chat\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1351a264-be5c-4fc0-83ba-55fe3136be4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-9 gcc-9\n",
      "  gcc-9-base libasan5 libatomic1 libbinutils libcc1-0 libctf-nobfd0 libctf0\n",
      "  libgcc-9-dev libgomp1 libisl22 libitm1 liblsan0 libmpc3 libmpfr6\n",
      "  libquadmath0 libtsan0 libubsan1\n",
      "Suggested packages:\n",
      "  binutils-doc cpp-doc gcc-9-locales gcc-multilib make manpages-dev autoconf\n",
      "  automake libtool flex bison gdb gcc-doc gcc-9-multilib gcc-9-doc\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-9 gcc gcc-9\n",
      "  gcc-9-base libasan5 libatomic1 libbinutils libcc1-0 libctf-nobfd0 libctf0\n",
      "  libgcc-9-dev libgomp1 libisl22 libitm1 liblsan0 libmpc3 libmpfr6\n",
      "  libquadmath0 libtsan0 libubsan1\n",
      "0 upgraded, 24 newly installed, 0 to remove and 16 not upgraded.\n",
      "Need to get 28.2 MB of archives.\n",
      "After this operation, 121 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 binutils-common amd64 2.34-6ubuntu1.6 [207 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libbinutils amd64 2.34-6ubuntu1.6 [473 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libctf-nobfd0 amd64 2.34-6ubuntu1.6 [47.4 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libctf0 amd64 2.34-6ubuntu1.6 [46.6 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.34-6ubuntu1.6 [1613 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 binutils amd64 2.34-6ubuntu1.6 [3376 B]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gcc-9-base amd64 9.4.0-1ubuntu1~20.04.2 [18.9 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libisl22 amd64 0.22.1-1 [592 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libmpfr6 amd64 4.0.2-1 [240 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libmpc3 amd64 1.1.0-1 [40.8 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 cpp-9 amd64 9.4.0-1ubuntu1~20.04.2 [7502 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 cpp amd64 4:9.3.0-1ubuntu2 [27.6 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcc1-0 amd64 10.5.0-1ubuntu1~20.04 [48.8 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgomp1 amd64 10.5.0-1ubuntu1~20.04 [102 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libitm1 amd64 10.5.0-1ubuntu1~20.04 [26.2 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libatomic1 amd64 10.5.0-1ubuntu1~20.04 [9284 B]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libasan5 amd64 9.4.0-1ubuntu1~20.04.2 [2752 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 liblsan0 amd64 10.5.0-1ubuntu1~20.04 [835 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libtsan0 amd64 10.5.0-1ubuntu1~20.04 [2016 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libubsan1 amd64 10.5.0-1ubuntu1~20.04 [785 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libquadmath0 amd64 10.5.0-1ubuntu1~20.04 [146 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgcc-9-dev amd64 9.4.0-1ubuntu1~20.04.2 [2359 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 gcc-9 amd64 9.4.0-1ubuntu1~20.04.2 [8276 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 gcc amd64 4:9.3.0-1ubuntu2 [5208 B]\n",
      "Fetched 28.2 MB in 3s (10.6 MB/s)0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package binutils-common:amd64.\n",
      "(Reading database ... 17208 files and directories currently installed.)\n",
      "Preparing to unpack .../00-binutils-common_2.34-6ubuntu1.6_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  1%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking binutils-common:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../01-libbinutils_2.34-6ubuntu1.6_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking libbinutils:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Selecting previously unselected package libctf-nobfd0:amd64.\n",
      "Preparing to unpack .../02-libctf-nobfd0_2.34-6ubuntu1.6_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  5%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libctf-nobfd0:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libctf0:amd64.\n",
      "Preparing to unpack .../03-libctf0_2.34-6ubuntu1.6_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libctf0:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../04-binutils-x86-64-linux-gnu_2.34-6ubuntu1.6_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking binutils-x86-64-linux-gnu (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 10%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../05-binutils_2.34-6ubuntu1.6_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking binutils (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package gcc-9-base:amd64.\n",
      "Preparing to unpack .../06-gcc-9-base_9.4.0-1ubuntu1~20.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking gcc-9-base:amd64 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Selecting previously unselected package libisl22:amd64.\n",
      "Preparing to unpack .../07-libisl22_0.22.1-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 15%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libisl22:amd64 (0.22.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../08-libmpfr6_4.0.2-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libmpfr6:amd64 (4.0.2-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../09-libmpc3_1.1.0-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libmpc3:amd64 (1.1.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Selecting previously unselected package cpp-9.\n",
      "Preparing to unpack .../10-cpp-9_9.4.0-1ubuntu1~20.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking cpp-9 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../11-cpp_4%3a9.3.0-1ubuntu2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 24%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Unpacking cpp (4:9.3.0-1ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../12-libcc1-0_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libcc1-0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package libgomp1:amd64.\n",
      "Preparing to unpack .../13-libgomp1_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Unpacking libgomp1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 29%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../14-libitm1_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libitm1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package libatomic1:amd64.\n",
      "Preparing to unpack .../15-libatomic1_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libatomic1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libasan5:amd64.\n",
      "Preparing to unpack .../16-libasan5_9.4.0-1ubuntu1~20.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 34%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking libasan5:amd64 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../17-liblsan0_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Unpacking liblsan0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libtsan0:amd64.\n",
      "Preparing to unpack .../18-libtsan0_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Unpacking libtsan0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 39%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../19-libubsan1_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking libubsan1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libquadmath0:amd64.\n",
      "Preparing to unpack .../20-libquadmath0_10.5.0-1ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking libquadmath0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package libgcc-9-dev:amd64.\n",
      "Preparing to unpack .../21-libgcc-9-dev_9.4.0-1ubuntu1~20.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libgcc-9-dev:amd64 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package gcc-9.\n",
      "Preparing to unpack .../22-gcc-9_9.4.0-1ubuntu1~20.04.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking gcc-9 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../23-gcc_4%3a9.3.0-1ubuntu2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 48%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking gcc (4:9.3.0-1ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up binutils-common:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libctf-nobfd0:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 53%]\u001b[49m\u001b[39m [##############################............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libgomp1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libmpfr6:amd64 (4.0.2-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 58%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libquadmath0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libmpc3:amd64 (1.1.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libatomic1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libubsan1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libisl22:amd64 (0.22.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libbinutils:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up libcc1-0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 72%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up liblsan0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up libitm1:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8Setting up gcc-9-base:amd64 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 77%]\u001b[49m\u001b[39m [############################################..............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8Setting up libtsan0:amd64 (10.5.0-1ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up libctf0:amd64 (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up libasan5:amd64 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Setting up cpp-9 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 86%]\u001b[49m\u001b[39m [#################################################.........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up binutils-x86-64-linux-gnu (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up binutils (2.34-6ubuntu1.6) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8Setting up libgcc-9-dev:amd64 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up cpp (4:9.3.0-1ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up gcc-9 (9.4.0-1ubuntu1~20.04.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 96%]\u001b[49m\u001b[39m [#######################################################...] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8Setting up gcc (4:9.3.0-1ubuntu2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8Processing triggers for libc-bin (2.31-0ubuntu9.12) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!sudo apt install gcc -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca57e292-775c-4128-8b32-ea39cc22073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"hi\", history=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b0edf4-e3dd-4524-bdb3-62d0a50b9fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? Is there anything specific you would like to talk about or ask me? I'm here to answer any questions you might have to the best of my ability.\n"
     ]
    }
   ],
   "source": [
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ed8a17-9fc9-40ce-b4d3-8c3fdf5ee988",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"Tell me a story about a young man who struggled to start a business and ultimately succeeded.\", history=history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007def01-22b4-4d74-98be-f67b278ff574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a young man named Jack who had always dreamed of starting his own business. He had a passion for entrepreneurship and loved the idea of being his own boss.\n",
      "Despite his enthusiasm, however, Jack struggled to get his business off the ground. He spent countless hours working on his business plan, but found it difficult to secure funding from investors. He also faced numerous setbacks and obstacles along the way, including competition from established companies and difficulties finding the right team members.\n",
      "Despite these challenges, Jack refused to give up on his dream. He continued to work tirelessly, networking with potential partners and customers, and constantly refining his business model. Slowly but surely, he began to see progress. His hard work paid off when he finally secured a significant investment from a group of angel investors.\n",
      "With this new infusion of capital, Jack was able to scale up his operations and hire more employees. He also began to generate buzz around his product, which helped him attract even more customers. As a result, his business started to grow rapidly, and within a few years, it had become a major player in its industry.\n",
      "Looking back on his journey, Jack realized that the key to his success had been perseverance and a willingness to learn from his mistakes. Despite the many obstacles he had faced, he had never given up on his dream, and as a result, he had achieved something truly remarkable.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a23d9b-94ed-4a21-beba-f6e056864c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The Persevering Entrepreneur\"\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Give this story a title in english\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48de9b69-fce7-4cba-8cd6-e2f26147dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2+2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"What is 2+2?\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b99903-cc33-4c96-b179-38bf2ff03d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematics and music may seem like vastly different disciplines, but they share many similarities when you look closely.\n",
      "\n",
      "Firstly, both mathematics and music have their own unique languages. In math, we use symbols, equations, and formulas to represent abstract concepts and ideas. Similarly, in music, we use notes, rhythms, and melodies to convey emotions and express ourselves.\n",
      "\n",
      "Secondly, both fields require creativity and imagination. Mathematicians often need to come up with new theorems or proofs, while musicians must compose original pieces or interpret existing ones in their own way. Both activities involve trial and error, experimentation, and the ability to think outside the box.\n",
      "\n",
      "Thirdly, there is an underlying structure and order to both math and music. Math has its own set of rules and principles that govern how numbers and equations interact with each other. Similarly, music follows specific patterns and structures such as time signatures, scales, and chord progressions. These frameworks provide a foundation for composers and performers to create within.\n",
      "\n",
      "Finally, both math and music can be appreciated on different levels. Basic arithmetic and simple songs can be understood by anyone, while more complex mathematical theories and virtuosic musical performances require specialized knowledge and training to fully appreciate.\n",
      "\n",
      "In conclusion, just as a beautiful piece of music can evoke strong emotions and stir our souls, so too can a elegant mathematical proof or theorem inspire awe and wonder at the beauty and complexity of the universe. Both math and music are universal languages that transcend culture and time, and continue to captivate us with their infinite possibilities.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Write a detailed analogy between mathematics and a music.\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "140c1e75-d446-4020-b86e-7ce7dadc0c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of England is London.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"What is the capital of England?\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad070c12-7915-41f7-a1f4-5650014488a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cafeteria had 23 apples, and used 20 for lunch, so they have $23 - 20 = 3$ apples left. They then bought 6 more apples, so now they have $3 + 6 = 9$ apples. Therefore, the cafeteria has 9 apples.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apple do they have?\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7694bfe-bab2-49ff-93ba-fb97ae321bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here is an implementation of the quicksort algorithm in Python:\n",
      "```\n",
      "def quicksort(arr):\n",
      "  if len(arr) <= 1:\n",
      "    return arr\n",
      "\n",
      "  pivot = arr[len(arr) // 2]\n",
      "  left = [x for x in arr if x < pivot]\n",
      "  middle = [x for x in arr if x == pivot]\n",
      "  right = [x for x in arr if x > pivot]\n",
      "\n",
      "  return quicksort(left) + middle + quicksort(right)\n",
      "\n",
      "print(quicksort([3,6,8,10,1,2,1]))\n",
      "# Output: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "This implementation uses the `len` function to determine the length of the input list and the `//` operator to perform integer division. It also uses a list comprehension to create the `left`, `middle`, and `right` lists.\n",
      "The `quicksort` function is called recursively on the `left` and `right` lists, which are then concatenated with the `middle` list to produce the final result.\n",
      "I hope this helps! Let me know if you have any questions.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"write quick sort in python\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0246bc30-8fc0-4f0d-8e02-1e35ba75d3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3d031cec7d49cf9317b328178202d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dddaee2c4cc450f95195f1144454653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenization_qwen.py:   0%|          | 0.00/9.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B-Chat:\n",
      "- tokenization_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d99421ccab434a86247cecd54e9a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "qwen.tiktoken:   0%|          | 0.00/2.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5de88a88-b315-438e-8699-6e7fe21cea9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3defa5214c9e4680aab060957dd27e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/910 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f246a68b1004d6b824926721ac5d3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_qwen.py:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B-Chat:\n",
      "- configuration_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1981521cd2cf4f42af4b2468096cef68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_qwen.py:   0%|          | 0.00/55.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0ee3d6522a4ff982bc348f03590b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cpp_kernels.py:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B-Chat:\n",
      "- cpp_kernels.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d19e0422684c87b90511371802c60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "qwen_generation_utils.py:   0%|          | 0.00/14.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B-Chat:\n",
      "- qwen_generation_utils.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/Qwen/Qwen-1_8B-Chat:\n",
      "- modeling_qwen.py\n",
      "- cpp_kernels.py\n",
      "- qwen_generation_utils.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97d12689f1a403883bf18cba82c1ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/14.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f701f2c3558141f4b0898f16d463583b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8854b6ce864c3cbc57a21a7e9665a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/2.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188a527508624a58ac50a59853a7b338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702185b1dc1b4907b93728055e9fdb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db12e433ee042679093056a15e41910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", device_map=\"auto\", trust_remote_code=True).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb3e1053-656e-4c8a-80d2-91af8c8a2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd60cb9c-c4a6-492a-9132-807f92e73dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today? Is there something on your mind that you would like to talk about or ask me a question? I'm here to provide information and answer any questions you may have to the best of my ability. Let me know how I can be of assistance!\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"hi\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7006fb5-c18d-480d-8324-03e93bab1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a young man named Jack who had big dreams of starting his own business. He had always been fascinated by technology and had spent countless hours tinkering with machines and software.\n",
      "But despite his passion and determination, it seemed impossible for him to get started. Jack had tried several different business ideas, but nothing ever seemed to take off. He felt lost and frustrated, wondering if he was too old or too inexperienced to succeed in this field.\n",
      "One day, Jack decided to take a break from his studies and focus on his career. He landed a job at a large tech company, where he learned the ropes of running a successful business.\n",
      "But no matter how much he learned, Jack couldn't shake the feeling that something was missing. He knew deep down that he wanted to start his own company, but he wasn't sure how.\n",
      "Finally, after years of contemplation and hard work, Jack realized that he needed to take the leap and quit his job. He left his secure position and set out on a journey to build his own company.\n",
      "It was not an easy road. Jack faced numerous obstacles and setbacks along the way, but he refused to give up. He worked tirelessly, pouring all of his energy into building his vision and creating a product that would make a real difference in people's lives.\n",
      "Finally, after months of hard work and dedication, Jack's dream became a reality. His product was launched and quickly gained popularity among customers. Jack realized that success was within reach, and he was overjoyed.\n",
      "From that day forward, Jack continued to run his company with passion and determination, always pushing himself to achieve greater heights. And though he faced many challenges along the way, he never forgot the lessons he learned from his struggles as a young man. He emerged stronger and more resilient than ever before, ready to tackle whatever challenges came his way.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Tell me a story about a young man who struggled to start a business and ultimately succeeded.\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb627091-fccc-419c-bc5a-de54858fcb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 2 and 2 is 4. \n",
      "\n",
      "To find the answer, you simply add the two numbers together: 2 + 2 = 4.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"What is 2+2?\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea95f88-c4fb-4129-af26-40b9604aaeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematics and music can be compared in many ways, as both involve complex systems and patterns that are difficult to describe with words alone.\n",
      "\n",
      "One way to think of mathematics is to compare it to a symphony orchestra. Just as an orchestra consists of multiple musicians playing different instruments at different times, mathematics involves multiple variables being combined to create solutions or models. Similarly, each musician in the orchestra adds their own unique sound to create a complete musical composition. However, unlike an orchestra, mathematics does not have time limits or strict rules for performance.\n",
      "\n",
      "Another analogy could be to compare mathematics to a painting. Just as a painting requires color, texture, and shape to create a visual image, mathematics involves combining different mathematical concepts and ideas to develop new solutions or theories. Each stroke or line in a painting represents a concept or idea, while each equation or formula represents a mathematical relationship between these concepts.\n",
      "\n",
      "Additionally, just like a painting can be interpreted in different ways by different viewers, mathematics can also be interpreted differently by different mathematicians. This is because mathematics is a vast field with many different branches and subfields, each with its own unique perspective and approach.\n",
      "\n",
      "Overall, both mathematics and music require creativity, imagination, and careful attention to detail to create beautiful and meaningful works. They are two sides of the same coin, representing the complexity and beauty of the natural world.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Write a detailed analogy between mathematics and a music.\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fa71482-f80c-4226-aedc-7f38dc1294d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an implementation of the Quick Sort algorithm in Python:\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "\n",
      "    pivot = arr[len(arr) // 2]\n",
      "    left = [x for x in arr if x < pivot]\n",
      "    middle = [x for x in arr if x == pivot]\n",
      "    right = [x for x in arr if x > pivot]\n",
      "\n",
      "    return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# Example usage\n",
      "arr = [3,6,8,10,1,2,1]\n",
      "sorted_arr = quick_sort(arr)\n",
      "print(sorted_arr)  # Output: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "The `quick_sort` function takes an array as input and returns a new array with the same elements sorted in ascending order. The function first checks if the length of the array is less than or equal to 1, in which case it returns the array itself since there are no duplicate elements to sort.\n",
      "Next, the function selects a pivot element from the array. This can be any value that will divide the remaining elements into three groups: values less than the pivot, values equal to the pivot, and values greater than the pivot. The pivot element is then stored in the `pivot` variable.\n",
      "Finally, the function recursively calls itself on the left and right subarrays of the array using the `quick_sort` function and concatenates the results with the pivot element to create the final sorted array.\n",
      "Note that this implementation assumes that the input array only contains integers. If the input array may contain non-integer values, you should add additional validation code to handle those cases appropriately.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"write quick sort in python\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69792d88-5f8a-447a-9654-2c302703ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They started with 23 apples and used 20 of them, so they have 23 - 20 = 3 apples left.\n",
      "Then they bought 6 more apples, bringing their total to 3 + 6 = 9 apples.\n",
      "\n",
      "Therefore, the answer is 9.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Answer the following question by reasoning step by step. The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apple do they have?\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18d22ddb-f5d1-411c-86c9-04c34bbd47fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital city of England is London. It is located on the River Thames and has been its official capital since 1066 when it was captured by King Harold II from Harold Godwinson, Duke of Normandy. London is one of the most populous cities in the world and is known for its rich history, iconic landmarks, and diverse culture.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"What is the capital of England?\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aac86d8-c532-4d1a-8a52-61b73eeb3e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Why we should open source GPT-4\n",
      "\n",
      "Dear Sam,\n",
      "\n",
      "I hope this email finds you well. I wanted to follow up on our conversation about the potential benefits of opening source GPT-4.\n",
      "\n",
      "Firstly, I believe that releasing GPT-4 as an open source project will allow for greater collaboration and innovation within the language model community. By sharing the codebase with others, researchers and developers can test, refine, and improve upon the model in ways that would be impossible with proprietary technology.\n",
      "\n",
      "Secondly, releasing GPT-4 as an open source project could help drive the growth of the AI research community. With more people accessing and using the model, it has the potential to attract more funding and resources, which could lead to further advancements and improvements in the field.\n",
      "\n",
      "Finally, by making GPT-4 freely available to the public, we can help ensure that the model is used for the betterment of society rather than just for profit. By enabling anyone to access and use the model, we can create a more inclusive and accessible technology that benefits everyone.\n",
      "\n",
      "Overall, I believe that releasing GPT-4 as an open source project is both necessary and beneficial. I look forward to seeing how this will play out.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Write a short email to Sam Altman giving reasons to open source GPT-4\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b10bd0f2-062a-4b1d-a82a-b6f6cbcc7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an example of how you can create a simple Snake game using Pygame:\n",
      "```\n",
      "import pygame\n",
      "\n",
      "# Set up the display and window\n",
      "pygame.init()\n",
      "screen = pygame.display.set_mode((800, 600))\n",
      "pygame.display.set_caption(\"Snake Game\")\n",
      "\n",
      "# Define the snake's movement\n",
      "snake_speed_x = 10\n",
      "snake_speed_y = -10\n",
      "\n",
      "# Define the food's position\n",
      "food_pos = (250, 250)\n",
      "\n",
      "# Create the snake\n",
      "snake = pygame.sprite.Group()\n",
      "\n",
      "# Set up the game loop\n",
      "running = True\n",
      "while running:\n",
      "    for event in pygame.event.get():\n",
      "        if event.type == pygame.QUIT:\n",
      "            running = False\n",
      "    \n",
      "    # Update the snake's position\n",
      "    snake.move(snake_speed_x, snake_speed_y)\n",
      "    \n",
      "    # Check for collisions with the walls\n",
      "    if snake.colliderect(screen):\n",
      "        running = False\n",
      "    \n",
      "    # Update the food's position\n",
      "    food_pos.x += snake.speed_x\n",
      "    food_pos.y += snake.speed_y\n",
      "    \n",
      "    # Draw the snake and food on the screen\n",
      "    screen.fill((255, 255, 255))\n",
      "    snake.draw(screen)\n",
      "    food.draw(screen)\n",
      "    \n",
      "    # Update the display\n",
      "    pygame.display.flip()\n",
      "\n",
      "# Quit Pygame\n",
      "pygame.quit()\n",
      "```\n",
      "\n",
      "This code creates a single snake that moves along the x-y axis at a constant speed (`snake_speed_x` and `snake_speed_y`). The snake collides with the walls of the screen by checking if it comes into contact with them. The food's position is updated every frame to follow the snake's movements.\n",
      "You can customize this code to add more functionality, such as allowing the player to control the snake using arrow keys or WASD keys, or adding a scoring system to keep track of how many frames the player has won. You can also use Pygame to add sound effects and visual effects to make the game more immersive.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, \"Write snake game in python using pygame\", history=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "869445fb-ad23-4680-a731-2bc21fe666e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''pygame 2.3.0 (SDL 2.24.2, Python 3.11.0)\n",
    "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/pradeep.borado/Downloads/a.py\", line 26, in <module>\n",
    "    snake.move(snake_speed_x, snake_speed_y)\n",
    "    ^^^^^^^^^^\n",
    "AttributeError: 'Group' object has no attribute 'move'. Did you mean: 'remove'?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3903f8f-f2d8-4945-b90c-25ed5da5eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error message \"AttributeError: 'Group' object has no attribute 'move'\" occurs when you try to access the `move()` method on a group object (such as the one created by `snake.move()`) but the group doesn't have that method.\n",
      "To fix this error, you will need to create the group object before calling the `move()` method. For example:\n",
      "```\n",
      "import pygame\n",
      "\n",
      "# Set up the display and window\n",
      "pygame.init()\n",
      "screen = pygame.display.set_mode((800, 600))\n",
      "pygame.display.set_caption(\"Snake Game\")\n",
      "\n",
      "# Create the snake\n",
      "snake_speed_x = 10\n",
      "snake_speed_y = -10\n",
      "\n",
      "# Create the group for the snake\n",
      "snake_group = pygame.sprite.Group()\n",
      "\n",
      "# Add the snake to the group\n",
      "snake_group.add(snake)\n",
      "\n",
      "# Set up the game loop\n",
      "running = True\n",
      "while running:\n",
      "    for event in pygame.event.get():\n",
      "        if event.type == pygame.QUIT:\n",
      "            running = False\n",
      "    \n",
      "    # Update the snake's position\n",
      "    snake_group.move(snake_speed_x, snake_speed_y)\n",
      "    \n",
      "    # Check for collisions with the walls\n",
      "    if snake.colliderect(screen):\n",
      "        running = False\n",
      "    \n",
      "    # Update the food's position\n",
      "    food_pos = (250, 250)\n",
      "\n",
      "    # Draw the snake and food on the screen\n",
      "    screen.fill((255, 255, 255))\n",
      "    snake_group.draw(screen)\n",
      "    food.draw(screen)\n",
      "    \n",
      "    # Update the display\n",
      "    pygame.display.flip()\n",
      "\n",
      "# Quit Pygame\n",
      "pygame.quit()\n",
      "```\n",
      "\n",
      "This code creates the snake group before adding it to the group, so the `move()` method can be called without any issues. You can then move the snake along the x-y axis at a constant speed (`snake_speed_x` and `snake_speed_y`).\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, q, history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ab5b06f-1b6a-43f5-b55d-23515874a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''pygame 2.3.0 (SDL 2.24.2, Python 3.11.0)\n",
    "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
    "Traceback (most recent call last):\n",
    "  File \"/Users/pradeep.borado/Downloads/b.py\", line 16, in <module>\n",
    "    snake_group.add(snake)\n",
    "                    ^^^^^\n",
    "NameError: name 'snake' is not defined'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "544bdc56-599c-4ea2-90b4-c8115a89d66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error message \"NameError: name 'snake' is not defined\" occurs when you try to call the `add()` method on an object of class `pygame.sprite.Group`, but that object doesn't have a `add()` method.\n",
      "To fix this error, you will need to create the group object before calling the `add()` method. For example:\n",
      "```\n",
      "import pygame\n",
      "\n",
      "# Set up the display and window\n",
      "pygame.init()\n",
      "screen = pygame.display.set_mode((800, 600))\n",
      "pygame.display.set_caption(\"Snake Game\")\n",
      "\n",
      "# Create the snake\n",
      "snake_speed_x = 10\n",
      "snake_speed_y = -10\n",
      "\n",
      "# Create the group for the snake\n",
      "snake_group = pygame.sprite.Group()\n",
      "\n",
      "# Add the snake to the group\n",
      "snake_group.add(snake)\n",
      "\n",
      "# Set up the game loop\n",
      "running = True\n",
      "while running:\n",
      "    for event in pygame.event.get():\n",
      "        if event.type == pygame.QUIT:\n",
      "            running = False\n",
      "    \n",
      "    # Update the snake's position\n",
      "    snake_group.move(snake_speed_x, snake_speed_y)\n",
      "    \n",
      "    # Check for collisions with the walls\n",
      "    if snake.colliderect(screen):\n",
      "        running = False\n",
      "    \n",
      "    # Update the food's position\n",
      "    food_pos = (250, 250)\n",
      "\n",
      "    # Draw the snake and food on the screen\n",
      "    screen.fill((255, 255, 255))\n",
      "    snake_group.draw(screen)\n",
      "    food.draw(screen)\n",
      "    \n",
      "    # Update the display\n",
      "    pygame.display.flip()\n",
      "\n",
      "# Quit Pygame\n",
      "pygame.quit()\n",
      "```\n",
      "\n",
      "This code creates the snake group before adding it to the group, so the `add()` method can be called without any issues. You can then add the snake to the group using the `add()` method, like this:\n",
      "```\n",
      "snake_group.add(snake)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, q, history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05474138-1350-447f-8790-82285cc21a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the complete code for creating a Snake game using Pygame:\n",
      "```\n",
      "import pygame\n",
      "\n",
      "# Set up the display and window\n",
      "pygame.init()\n",
      "screen = pygame.display.set_mode((800, 600))\n",
      "pygame.display.set_caption(\"Snake Game\")\n",
      "\n",
      "# Create the snake\n",
      "snake_speed_x = 10\n",
      "snake_speed_y = -10\n",
      "\n",
      "# Create the group for the snake\n",
      "snake_group = pygame.sprite.Group()\n",
      "\n",
      "# Add the snake to the group\n",
      "snake_group.add(snake)\n",
      "\n",
      "# Set up the game loop\n",
      "running = True\n",
      "while running:\n",
      "    for event in pygame.event.get():\n",
      "        if event.type == pygame.QUIT:\n",
      "            running = False\n",
      "    \n",
      "    # Update the snake's position\n",
      "    snake_group.move(snake_speed_x, snake_speed_y)\n",
      "    \n",
      "    # Check for collisions with the walls\n",
      "    if snake.colliderect(screen):\n",
      "        running = False\n",
      "    \n",
      "    # Update the food's position\n",
      "    food_pos = (250, 250)\n",
      "\n",
      "    # Draw the snake and food on the screen\n",
      "    screen.fill((255, 255, 255))\n",
      "    snake_group.draw(screen)\n",
      "    food.draw(screen)\n",
      "    \n",
      "    # Update the display\n",
      "    pygame.display.flip()\n",
      "\n",
      "# Quit Pygame\n",
      "pygame.quit()\n",
      "```\n",
      "\n",
      "This code creates a single snake that moves along the x-y axis at a constant speed (`snake_speed_x` and `snake_speed_y`). The snake collides with the walls of the screen by checking if it comes into contact with them. The food's position is updated every frame to follow the snake's movements.\n",
      "You can customize this code to add more functionality, such as allowing the player to control the snake using arrow keys or WASD keys, or adding a scoring system to keep track of how many frames the player has won. You can also use Pygame to add sound effects and visual effects to make the game more immersive.\n"
     ]
    }
   ],
   "source": [
    "response, history = model.chat(tokenizer, 'give me the full correct working code', history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c93bc-abfd-4118-80f7-d2ecd2b43134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
