{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a36ccc-819f-4a9e-aceb-3d694446fff5",
   "metadata": {},
   "source": [
    "Beast Cookbook: Use the LLM to generate a full, fictional \"Mr. Beast Cookbook\" with recipes that incorporate elements from his challenges and stunts. The recipes could have humorous, pun-filled names and absurd, over-the-top ingredients lists.\n",
    "\n",
    "The \"Beast Cookbook\" idea is a creative way to engage with Mr. Beast's content by generating a fictional cookbook inspired by his over-the-top challenges and stunts. By leveraging a large language model (LLM), you can create a collection of wild, whimsical recipes that capture the spirit of his videos.\n",
    "\n",
    "The LLM can help generate humorous recipe names, absurd ingredients lists, and entertaining instructions that reference specific moments from Mr. Beast's channel. The cookbook could be organized into sections based on different types of challenges or themes, and include engaging elements like illustrations, pun-filled captions, or fictitious testimonials.\n",
    "\n",
    "The \"Beast Cookbook\" could serve as a standalone piece of content or a promotional tool to drive engagement with Mr. Beast's channel. It's a clever way to transform video content into a new, amusing format that showcases the creativity and humor of his brand, and can be enjoyed by his fans in various forms, such as a digital download or limited-edition physical merchandise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ba969a-f0f0-4cac-97c1-903ddf586343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  sentence_transformers > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b685e9ba-b097-4a88-9e85-a951b6164bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.57.tar.gz (36.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting langchain-nomic\n",
      "  Downloading langchain_nomic-0.0.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.0.30-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python) (4.10.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python) (1.26.2)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from llama-cpp-python) (3.1.3)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain-nomic)\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting nomic<4.0.0,>=3.0.12 (from langchain-nomic)\n",
      "  Downloading nomic-3.0.15.tar.gz (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Downloading SQLAlchemy-2.0.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from langchain_community) (3.9.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
      "  Downloading langsmith-0.1.31-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240311-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from chromadb) (2.6.4)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from chromadb) (0.110.0)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.28.0)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from chromadb) (1.62.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: packaging>=19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (24.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.28.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-nomic) (4.3.0)\n",
      "Collecting packaging>=19.0 (from build>=1.0.3->chromadb)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.1.7)\n",
      "Collecting jsonlines (from nomic<4.0.0,>=3.0.12->langchain-nomic)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting loguru (from nomic<4.0.0,>=3.0.12->langchain-nomic)\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (13.7.1)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.1.4)\n",
      "Requirement already satisfied: pyarrow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (15.0.1)\n",
      "Requirement already satisfied: pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (10.2.0)\n",
      "Requirement already satisfied: pyjwt in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.8.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Requirement already satisfied: protobuf in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.4)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-nomic) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-nomic) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.17.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Downloading langchain_nomic-0.0.2-py3-none-any.whl (3.4 kB)\n",
      "Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-0.0.30-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.1.1-py3-none-any.whl (19 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.31.0.20240311-py3-none-any.whl (14 kB)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Building wheels for collected packages: llama-cpp-python, nomic, pypika\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.57-cp310-cp310-manylinux_2_31_x86_64.whl size=2850208 sha256=844bc10b7cae76d9ed522e17d1e5060bd9471180f8e797b294bd203052a37831\n",
      "  Stored in directory: /teamspace/studios/this_studio/.cache/pip/wheels/7e/c0/00/e98d6e198f941c623da37b3f674354cbdccfcfb2cb9cf1133d\n",
      "  Building wheel for nomic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nomic: filename=nomic-3.0.15-py3-none-any.whl size=42091 sha256=aaa776a8cd3c532f292ae86492919b094d17e89a067c8f8ae096b16bd28f9d6b\n",
      "  Stored in directory: /teamspace/studios/this_studio/.cache/pip/wheels/d2/98/15/9adf9ab3278947c30b5fed4a8dd056de4f9de08de6635c5016\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=bb8746393c71ef005992cdae24702ccc21f51e1ba3b4c1407c288b37e02e205e\n",
      "  Stored in directory: /teamspace/studios/this_studio/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built llama-cpp-python nomic pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, uvloop, types-requests, typer, tenacity, regex, python-dotenv, pyproject_hooks, pulsar-client, packaging, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, loguru, jsonpatch, jsonlines, importlib-resources, humanfriendly, httptools, greenlet, googleapis-common-protos, diskcache, chroma-hnswlib, bcrypt, asgiref, watchfiles, typing-inspect, tiktoken, SQLAlchemy, posthog, opentelemetry-exporter-otlp-proto-common, marshmallow, llama-cpp-python, langchainhub, importlib-metadata, huggingface_hub, deprecated, coloredlogs, build, tokenizers, opentelemetry-api, onnxruntime, nomic, langsmith, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langgraph, langchain-text-splitters, langchain-nomic, langchain_community, opentelemetry-instrumentation-fastapi, langchain, chromadb\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed SQLAlchemy-2.0.28 asgiref-3.8.1 bcrypt-4.1.2 build-1.1.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 diskcache-5.6.3 flatbuffers-24.3.7 googleapis-common-protos-1.63.0 greenlet-3.0.3 httptools-0.6.1 huggingface_hub-0.21.4 humanfriendly-10.0 importlib-metadata-6.11.0 importlib-resources-6.4.0 jsonlines-4.0.0 jsonpatch-1.33 kubernetes-29.0.0 langchain-0.1.13 langchain-core-0.1.33 langchain-nomic-0.0.2 langchain-text-splitters-0.0.1 langchain_community-0.0.29 langchainhub-0.1.15 langgraph-0.0.30 langsmith-0.1.31 llama-cpp-python-0.2.57 loguru-0.7.2 marshmallow-3.21.1 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 nomic-3.0.15 onnxruntime-1.17.1 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 packaging-23.2 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 regex-2023.12.25 tenacity-8.2.3 tiktoken-0.6.0 tokenizers-0.15.2 typer-0.9.0 types-requests-2.31.0.20240311 typing-inspect-0.9.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0 wrapt-1.16.0 zipp-3.18.1\n"
     ]
    }
   ],
   "source": [
    "! pip install -U llama-cpp-python langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e422c5-9566-4798-a6b6-9c5a1b2995cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39b60b63-8cdd-4da7-98e1-7bd96634d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_mistralai -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7abd2505-8334-40d5-9120-82ca72817d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786a6c80-17dd-4414-8709-e13a12cfd609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>views</th>\n",
       "      <th>length</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE WORST SONG ON YOUTUBE *CRINGE*</td>\n",
       "      <td>THE WORST SONG ON YOUTUBE *CRINGE*\\n\\n What's ...</td>\n",
       "      <td>771458</td>\n",
       "      <td>247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is a song about bad teammates in COD \\n\\n...</td>\n",
       "      <td>['the worst song on youtube', 'cringiest song ...</td>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>https://i.ytimg.com/vi/yozl6enFC-w/sddefault.jpg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Surviving 24 Hours Straight In The Bermuda Tri...</td>\n",
       "      <td>Surviving 24 Hours Straight In The Bermuda Tri...</td>\n",
       "      <td>152738695</td>\n",
       "      <td>701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THIS IS ONE OF THE CRAZIEST THINGS I'VE EVER D...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-11-09</td>\n",
       "      <td>https://i.ytimg.com/vi/D9lVNzyhYnc/sddefault.jpg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Hope This Magic Trick Works</td>\n",
       "      <td>I Hope This Magic Trick Works\\n\\n Welcome back...</td>\n",
       "      <td>41925793</td>\n",
       "      <td>982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WE ATTEMPTED POPULAR MAGIC TRICKS AND THIS HAP...</td>\n",
       "      <td>['magic tricks', 'magic trick', 'experiment', ...</td>\n",
       "      <td>2018-09-11</td>\n",
       "      <td>https://i.ytimg.com/vi/tBEBc4KQVsU/sddefault.jpg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Important Youtube Announcement (please watch)</td>\n",
       "      <td>Important Youtube Announcement (please watch)\\...</td>\n",
       "      <td>34218111</td>\n",
       "      <td>155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I CAN'T BELIEVE WE REACHED OUR GOAL!!!!! YOU G...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>https://i.ytimg.com/vi/0hVZOJCYBBM/sddefault.jpg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every Challenge I've Ever Done</td>\n",
       "      <td>Every Challenge I've Ever Done\\n\\n Welcome to ...</td>\n",
       "      <td>820648</td>\n",
       "      <td>85686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is basically my life in a nutshell\\n\\nSUB...</td>\n",
       "      <td>['counting to 100000', 'reading the bee movie ...</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>https://i.ytimg.com/vi/KcsRxHwGz7A/sddefault.jpg</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>UCX6OQ3DkcsbYNE6H8uQQuVA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                 THE WORST SONG ON YOUTUBE *CRINGE*   \n",
       "1  Surviving 24 Hours Straight In The Bermuda Tri...   \n",
       "2                      I Hope This Magic Trick Works   \n",
       "3      Important Youtube Announcement (please watch)   \n",
       "4                     Every Challenge I've Ever Done   \n",
       "\n",
       "                                          transcript      views  length  \\\n",
       "0  THE WORST SONG ON YOUTUBE *CRINGE*\\n\\n What's ...     771458     247   \n",
       "1  Surviving 24 Hours Straight In The Bermuda Tri...  152738695     701   \n",
       "2  I Hope This Magic Trick Works\\n\\n Welcome back...   41925793     982   \n",
       "3  Important Youtube Announcement (please watch)\\...   34218111     155   \n",
       "4  Every Challenge I've Ever Done\\n\\n Welcome to ...     820648   85686   \n",
       "\n",
       "   rating                                        description  \\\n",
       "0     NaN  This is a song about bad teammates in COD \\n\\n...   \n",
       "1     NaN  THIS IS ONE OF THE CRAZIEST THINGS I'VE EVER D...   \n",
       "2     NaN  WE ATTEMPTED POPULAR MAGIC TRICKS AND THIS HAP...   \n",
       "3     NaN  I CAN'T BELIEVE WE REACHED OUR GOAL!!!!! YOU G...   \n",
       "4     NaN  This is basically my life in a nutshell\\n\\nSUB...   \n",
       "\n",
       "                                            keywords publish_date  \\\n",
       "0  ['the worst song on youtube', 'cringiest song ...   2016-08-08   \n",
       "1                                                 []   2019-11-09   \n",
       "2  ['magic tricks', 'magic trick', 'experiment', ...   2018-09-11   \n",
       "3                                                 []   2019-12-28   \n",
       "4  ['counting to 100000', 'reading the bee movie ...   2017-06-23   \n",
       "\n",
       "                                      thumbnail_url channel_title  \\\n",
       "0  https://i.ytimg.com/vi/yozl6enFC-w/sddefault.jpg       MrBeast   \n",
       "1  https://i.ytimg.com/vi/D9lVNzyhYnc/sddefault.jpg       MrBeast   \n",
       "2  https://i.ytimg.com/vi/tBEBc4KQVsU/sddefault.jpg       MrBeast   \n",
       "3  https://i.ytimg.com/vi/0hVZOJCYBBM/sddefault.jpg       MrBeast   \n",
       "4  https://i.ytimg.com/vi/KcsRxHwGz7A/sddefault.jpg       MrBeast   \n",
       "\n",
       "                 channel_id  \n",
       "0  UCX6OQ3DkcsbYNE6H8uQQuVA  \n",
       "1  UCX6OQ3DkcsbYNE6H8uQQuVA  \n",
       "2  UCX6OQ3DkcsbYNE6H8uQQuVA  \n",
       "3  UCX6OQ3DkcsbYNE6H8uQQuVA  \n",
       "4  UCX6OQ3DkcsbYNE6H8uQQuVA  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mrbeast.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47fd1ca-a786-4bfb-a1ff-9a82b62e2b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I Cleaned The World’s Dirtiest Beach #TeamSeas\n",
      "\n",
      " This is one of the dirtiest beaches in the entire w\n"
     ]
    }
   ],
   "source": [
    "print(df['transcript'].iloc[10][:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2f5c72e-fe6a-4a9d-9621-e5a78d8b32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"mistral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "132efc44-9ed8-43cb-8781-211d53a92a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "doc =  Document(page_content=df['transcript'].iloc[100], metadata={\"source\": \"local\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57fb55e6-01c3-47d0-9e03-a9d024e78853",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for d in df['transcript']:\n",
    "    doc =  Document(page_content=d, metadata={\"source\": \"local\"})\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2250f1c1-0784-49b5-b29e-b2c45bb9992d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import LlamaCppEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=100\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a57dbea-e9b7-410b-9728-b918efcf6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Index\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efae5226-88ab-4477-8c2e-529776b63954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    return {\"keys\": {\"documents\": documents, \"question\": question}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c989aa37-d547-4345-89e0-5da91f4a9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "\n",
    "local = False\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    state_dict = state[\"keys\"]\n",
    "    question = state_dict[\"question\"]\n",
    "    documents = state_dict[\"documents\"]\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    if local:\n",
    "            llm = Ollama(model=local_llm, temperature=0.6)\n",
    "    else:\n",
    "        llm = ChatMistralAI(mistral_api_key='', model = 'mistral-tiny')\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\n",
    "        \"keys\": {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b773517-54b2-4dcb-9240-3ee6cb25f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_food_elements():\n",
    "    state = {\n",
    "        \"keys\":{\n",
    "            \"question\": \"Identify food items, ingredients, or eating challenges mentioned\"\n",
    "        }\n",
    "    }\n",
    "    state = retrieve(state)\n",
    "    state = generate(state)\n",
    "    food_elements = state['keys']['generation']\n",
    "    return food_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a70bd5e-bb42-4eef-b482-dd91b712c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "---GENERATE---\n"
     ]
    }
   ],
   "source": [
    "food_elements = get_food_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2a3e28b-8569-4aa2-ac6f-6778b5321b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context mentions various food items such as cherrywood smoked bacon, apple wood bacon, fried chicken, red eye gravy, mashed potatoes, Ecuadorian chocolate tart, wide-ass salmon, Mac and Cheese, peanuts, scrambled eggs, sandwiches, and hot dogs. There are also mentions of food banks and people who are food insecure during the Covid outbreak.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5f207d4-90cf-4327-b1e3-8d4a4c5b44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Recipes(BaseModel):\n",
    "    names: List = Field(description=\"the list of recipe names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409234ef-2197-4328-9a43-7a9d966759ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "024ebb89-62f3-4641-a649-5d5243e21817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_names(food_elements):\n",
    "    parser = PydanticOutputParser(pydantic_object=Recipes)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    \n",
    "    llm = ChatMistralAI(mistral_api_key='', model = 'mistral-tiny')\n",
    "    chain = prompt | llm | parser\n",
    "    recipes = chain.invoke({\"query\": f'''Given the following information {food_elements} \n",
    "    Generate pun-filled, humorous recipe names. \n",
    "    For example, if a video featured a giant pizza challenge, the LLM might create a recipe called \"Beastly Behemoth Supreme Pizza.'''})\n",
    "    return recipes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e70b9191-4a8e-4a86-a490-e92df9204f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_names = get_recipe_names(food_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd4ab43-a10b-406d-a5a0-babe69cf7b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cherrybacon Delight: The Wood-Smoked Wondrousness', 'Apple-wood Apple-dacious Bacon Bites', 'Fowl Play: Crispy Fried Chicken Cha-Cha', \"Red-Eyed Rooster's Revenge: Red Eye Gravy Galore\", 'Mashed Potato Palava: Spudtastic Surprise', 'Ecuadorian Choco-Laugh: Tarty Temptation', 'Salmon Swim: Wide-ass Wonderfish', 'Mac Attack: Cheesy Mac and Cheese Marvel', 'Peanut Pranksters: Crunchy Craving Crusaders', 'Scrambled Eggscelence: Sunny Side Up Surprise', 'Sammiches and Hot Dogs: Deli Delights', 'Hunger Helpers: Food Bank Feast', 'Covid Cravings: Recipes for the Food Insecure']\n"
     ]
    }
   ],
   "source": [
    "print(recipe_names.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38a492aa-4dd2-4b9d-8dd0-26cd6b251b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Ingredients(BaseModel):\n",
    "    ingredients: List[str] = Field(description=\"the list of ingredients\")\n",
    "\n",
    "def get_ingredients(recipe_name):\n",
    "    parser = PydanticOutputParser(pydantic_object=Ingredients)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    \n",
    "    llm = ChatMistralAI(mistral_api_key='', model = 'mistral-tiny')\n",
    "    chain = prompt | llm | parser\n",
    "    ing = chain.invoke({\"query\": f'''Given the following  recipe name {recipe_name}\n",
    "        Create ingredient lists: For each recipe name, have the LLM generate an absurd, over-the-top list of ingredients. \n",
    "        Encourage the LLM to include ridiculous quantities, unexpected flavor combinations, and ingredients that tie back to specific challenges or stunts.'''})\n",
    "    return ing.ingredients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9031e94-4202-41e4-85cf-5c312f611dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rps = []\n",
    "for name in recipe_names.names:\n",
    "    recipe = {\n",
    "        \"name\": name\n",
    "    }\n",
    "    rps.append(recipe)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "663e4559-7b55-40af-8855-f0be836d261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rps:\n",
    "    ingredients = get_ingredients(r['name'])\n",
    "    r['ingredients'] = ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf55a385-7525-4138-b6f9-a569fbfaa73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Cherrybacon Delight: The Wood-Smoked Wondrousness',\n",
       " 'ingredients': ['100 lbs of fresh, juicy cherries, pitted and halved',\n",
       "  '50 lbs of crispy bacon, cooked until extra crispy',\n",
       "  '2 gallons of pure maple syrup',\n",
       "  '1 lb of ground cinnamon',\n",
       "  '50 lbs of brown sugar',\n",
       "  '100 lbs of unsalted butter',\n",
       "  '50 lbs of smoked sea salt',\n",
       "  '25 lbs of black pepper, freshly ground',\n",
       "  '50 lbs of chili powder',\n",
       "  '100 lbs of marshmallows',\n",
       "  '1 ton of graham crackers, crushed',\n",
       "  '50 lbs of dark chocolate, chopped',\n",
       "  '10 cans of whipped cream',\n",
       "  '10 bottles of hot sauce, for garnish',\n",
       "  '1 can of baked beans, for added texture',\n",
       "  '1 bottle of olive oil, for wood-smoking',\n",
       "  '1 bag of hickory chips, for wood-smoking',\n",
       "  '1 container of edible glitter, for a festive touch']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5187ae3d-d169-40e0-98ee-3eb3eab99939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instructions(BaseModel):\n",
    "    instructions: List[str] = Field(description=\"the list of instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70082b21-3c99-4792-a0c4-d3123fc3777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_instructions(recipe):\n",
    "    parser = PydanticOutputParser(pydantic_object=Instructions)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    \n",
    "    llm = ChatMistralAI(mistral_api_key='', model = 'mistral-small')\n",
    "    chain = prompt | llm | parser\n",
    "    question = f'''Given the following recipe {recipe['name']} and ingredients {recipe['ingredients']} \n",
    "        Write recipe instructions: Feed the recipe names and ingredient lists into the LLM and have it generate step-by-step instructions for each dish.\n",
    "        The instructions should be a mix of practical cooking steps and humorous, exaggerated descriptions that reference Mr. Beast's antics.\n",
    "        '''\n",
    "    ins = chain.invoke({\"query\": question})\n",
    "    return ins.instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "421d2026-343a-44ef-82ca-472cd9ab3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rps:\n",
    "    instructions = get_recipe_instructions(r)\n",
    "    r['instructions'] = instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9136211-f383-4e1e-bfbc-8fd79b5fc450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Gather the key ingredients for Cherrybacon Delight, including a staggering 100 lbs of fresh, juicy cherries, 50 lbs of crispy bacon, 2 gallons of pure maple syrup, 1 lb of ground cinnamon, 50 lbs of brown sugar, 100 lbs of unsalted butter, 50 lbs of smoked sea salt, 25 lbs of black pepper, 50 lbs of chili powder, 100 lbs of marshmallows, 1 ton of crushed graham crackers, 50 lbs of chopped dark chocolate, 10 cans of whipped cream, 10 bottles of hot sauce, 1 can of baked beans, 1 bottle of olive oil, 1 bag of hickory chips, and 1 container of edible glitter for a festive touch. Don't forget to channel your inner Mr. Beast and think big!\n",
      "-------------------------------------------------------------------------------------\n",
      "Step 2: Begin by wood-smoking the cherries and bacon using the hickory chips and olive oil to infuse them with a rich, smoky flavor. As Mr. Beast would say, 'Go big or go home' – let's make this a 24-hour smoke fest to really lock in the flavors!\n",
      "-------------------------------------------------------------------------------------\n",
      "Step 3: In a pan large enough to fit a small car, melt the butter, brown sugar, and maple syrup together until it reaches a consistency that can only be described as 'liquid gold.' Add the smoked cherries, bacon, and spices, stirring until the mixture resembles a fruity, smoky, spicy paradise.\n",
      "-------------------------------------------------------------------------------------\n",
      "Step 4: Invite your friends over for a marshmallow roasting party, but not just any roasting party – a roof-raising, earth-shaking, Mr. Beast-style event! Roast the marshmallows until they reach a perfect golden hue, then add them to the cherrybacon mixture along with the crushed graham crackers, chopped dark chocolate, and baked beans for added texture.\n",
      "-------------------------------------------------------------------------------------\n",
      "Step 5: As you layer the Cherrybacon Delight in a colossal pan, take a moment to appreciate your culinary masterpiece. Sprinkle the edible glitter over the top for a touch of whimsy, because as Mr. Beast always says, 'You only live once, so make it memorable!'\n",
      "-------------------------------------------------------------------------------------\n",
      "Step 6: Invite the entire neighborhood to share in your Cherrybacon Delight, because food this extraordinary deserves to be enjoyed by all! And remember, as Mr. Beast would say, 'If you're going to do something, do it big!'\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in rps[0]['instructions']:\n",
    "    print(i)\n",
    "    print('-------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f19b287-3437-4cbd-a7bd-6bad36d5dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e8f3fd7-8b6f-4f32-9cd0-5b6f73b2455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Suggestions(BaseModel):\n",
    "    suggestions: List[str] = Field(description=\"the list of serving suggestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe6bedd8-fbfe-4e66-92d1-424ac1752e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_serving_suggestions(recipe):\n",
    "    parser = PydanticOutputParser(pydantic_object=Suggestions)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    \n",
    "    llm = ChatMistralAI(mistral_api_key='', model = 'mistral-tiny')\n",
    "    chain = prompt | llm | parser\n",
    "    question = f'''\n",
    "        You are given the following information recipe name {recipe['name']} \n",
    "        Generate serving suggestions: Have the LLM create amusing, tongue-in-cheek serving suggestions for each recipe. \n",
    "        These could include things like \"Serve on a golden platter to 10,000 of your closest friends\" or \"Pair with a refreshing 100-gallon soda challenge.\n",
    "        '''\n",
    "    ins = chain.invoke({\"query\": question})\n",
    "    return ins.suggestions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e584a38-3512-444b-bf0d-1c8f39152837",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rps:\n",
    "    suggestions = get_serving_suggestions(r)\n",
    "    r['suggestions'] = suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfc14e6c-067f-49bf-9629-8364585616bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rps:\n",
    "    r['serving_suggestion'] = r['suggestions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8ec2dd8-13b6-4f4a-a9c1-e659e6dc034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Serve Cherrybacon Delight to your royal court as a sign of your culinary excellence.',\n",
       " 'Pair this Wood-Smoked Wondrousness with a refreshing 50-gallon soda challenge for a truly memorable experience.',\n",
       " 'Have your guests guess the number of cherries in each bite before they take a taste.',\n",
       " 'Serve Cherrybacon Delight on a golden platter to 10,000 of your closest friends.',\n",
       " 'Create a cherrybacon delight flavor ice cream and serve it as a dessert.',\n",
       " 'Serve Cherrybacon Delight with a side of wood-smoked laughter to enhance the flavor experience.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps[0]['suggestions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acb55694-f391-4ff0-8423-e1a4a8856326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7873\n",
      "Running on public URL: https://ac2aa33530bd9b22f9.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ac2aa33530bd9b22f9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the recipe data\n",
    "recipes = rps\n",
    "intro = \"\"\"\n",
    "    <div style=\"text-align: center; color: #8e44ad;background-color: #f8d49e; padding: 20px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);\">\n",
    "        <h1 style=\"color: #8e44ad; font-size: 36px; margin-bottom: 20px;\">Welcome to the Beast Cookbook!</h1>\n",
    "        <p style=\"color: #8e44ad; font-size: 18px;\">Prepare yourself for a wild culinary adventure inspired by Mr. Beast's epic food challenges. \n",
    "        This cookbook is filled with larger-than-life recipes that will push your cooking skills to the limit.\n",
    "        Get ready to conquer the kitchen like a true Beast!</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "outro = \"\"\"\n",
    "    <div style=\"text-align: center; background-color: #c8d6e5; color: #8e44ad;padding: 20px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);\">\n",
    "        <h2 style=\"color: #8e44ad; font-size: 28px; margin-bottom: 20px;\">Congratulations, you've reached the end of the Beast Cookbook!</h2>\n",
    "        <p style=\"color: #8e44ad; font-size: 18px;\">We hope you've enjoyed this whimsical culinary journey inspired by Mr. Beast's over-the-top food challenges.\n",
    "        Now it's time for you to take on your own kitchen adventures and create some truly unforgettable meals.\n",
    "        Remember, cooking is all about having fun and pushing boundaries. So go forth and be a Beast in the kitchen!</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "def display_recipe(recipe_index):\n",
    "    if recipe_index < 0 or recipe_index >= len(recipes):\n",
    "        return \"Recipe not found.\"\n",
    "    \n",
    "    recipe = recipes[recipe_index]\n",
    "    return f\"\"\"\n",
    "        <div style=\"background-color: #f5f5f5; padding: 20px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);\">\n",
    "            <h2 style=\"color: #e67e22; font-size: 32px; margin-bottom: 20px;\">{recipe['name']}</h2>\n",
    "            <h3 style=\"color: #2c3e50; font-size: 24px; margin-top: 30px;\">Ingredients:</h3>\n",
    "            <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "                {\"\".join([f'<li style=\"margin-bottom: 10px;color: #8e44ad;\"><span style=\"color: #8e44ad; font-size: 18px; margin-right: 10px;\">•</span>{ingredient}</li>' for ingredient in recipe['ingredients']])}\n",
    "            </ul>\n",
    "            <h3 style=\"color: #2c3e50; font-size: 24px; margin-top: 30px;\">Instructions:</h3>\n",
    "            <ol style=\"padding-left: 20px;\">\n",
    "                {\"\".join([f'<li style=\"margin-bottom: 10px; color: #8e44ad; font-size: 18px;\">{step}</li>' for step in recipe['instructions']])}\n",
    "            </ol>\n",
    "            <h3 style=\"color: #2c3e50; font-size: 24px; margin-top: 30px;\">Serving Suggestion:</h3>\n",
    "            <p style=\"color: #d35400; font-size: 18px; font-style: italic;\">{recipe['serving_suggestion']}</p>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "\n",
    "recipe_index = 0\n",
    "\n",
    "def cookbook(action):\n",
    "    global recipe_index\n",
    "    if action == \"Next\":\n",
    "        recipe_index = (recipe_index + 1) % len(recipes)\n",
    "    elif action == \"Previous\":\n",
    "        recipe_index = (recipe_index - 1) % len(recipes)\n",
    "    \n",
    "    if recipe_index == 0:\n",
    "        return intro + display_recipe(recipe_index)\n",
    "    elif recipe_index == len(recipes) - 1:\n",
    "        return display_recipe(recipe_index) + outro\n",
    "    else:\n",
    "        return display_recipe(recipe_index)\n",
    "\n",
    "with gr.Blocks(theme=\"default\") as blocks:\n",
    "    # Injecting CSS for custom styling\n",
    "    gr.HTML(value=\"\"\"\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                background-color: #f9f9f9; /* Light grey background */\n",
    "                color: #333; /* Dark grey text */\n",
    "            }\n",
    "            .gr-blocks-container, .gradio-container {\n",
    "                max-width: 800px;\n",
    "                margin: 20px auto;\n",
    "                padding: 20px;\n",
    "                background-color: #fff; /* White background for the container */\n",
    "                border-radius: 10px;\n",
    "                box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "            }\n",
    "            /* Custom styles for Markdown components */\n",
    "            h1, p {\n",
    "                color: #31708e; /* Dark cyan text for headings and paragraphs */\n",
    "            }\n",
    "            h1 {\n",
    "                background-color: #d9edf7; /* Light cyan background for headings */\n",
    "            }\n",
    "            p {\n",
    "                background-color: #fefefe; /* Very light grey background for paragraphs */\n",
    "            }\n",
    "        </style>\n",
    "    \"\"\", visible=False)\n",
    "    \n",
    "   \n",
    "    prev_button = gr.Button(\"Previous\")\n",
    "    next_button = gr.Button(\"Next\")\n",
    "    output_html = gr.HTML()\n",
    "    prev_button.click(cookbook, inputs=[prev_button], outputs=[output_html])\n",
    "    next_button.click(cookbook, inputs=[next_button], outputs=[output_html])\n",
    "    output_html.value=display_recipe(0)\n",
    "    navigate.change(cookbook, inputs=navigate, outputs=output_html)\n",
    "\n",
    "\n",
    "blocks.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a36605-7b8d-47c4-998b-b4f1b55343d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
